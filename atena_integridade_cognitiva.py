"""
Sistema de Integridade Cognitiva da Atena
=========================================

M√≥dulo para preven√ß√£o e gerenciamento de alucina√ß√µes em IA atrav√©s de 
arquitetura multi-camadas de verifica√ß√£o e autorreflex√£o cont√≠nua.

Autor: Sistema de Desenvolvimento da Atena
Data: 2025-06-23
"""

import asyncio
import json
import logging
import math
import re
import statistics
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from collections import defaultdict
import numpy as np

# Depend√™ncias externas (instalar via pip)
try:
    import spacy
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import requests
except ImportError as e:
    print(f"Depend√™ncia n√£o encontrada: {e}")
    print("Instale as depend√™ncias: pip install spacy sentence-transformers requests scikit-learn")
    print("E execute: python -m spacy download pt_core_news_sm")


@dataclass
class ResultadoValidacao:
    """Resultado da valida√ß√£o de integridade cognitiva"""
    nivel_integridade: str
    decisao_final: str
    score_confianca: float
    score_ancoragem: float
    relatorio_fatos: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    contexto_analisado: str = ""
    insights_gerados: List[str] = field(default_factory=list)


class UncertaintyAnalyzer:
    """
    Filtro 1: An√°lise de Incerteza do Modelo
    Mede a confian√ßa intr√≠nseca do modelo em sua pr√≥pria gera√ß√£o
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__ + '.UncertaintyAnalyzer')
    
    def calcular_entropia(self, logprobs: List[float]) -> float:
        """Calcula a entropia da distribui√ß√£o de probabilidades"""
        if not logprobs:
            return 1.0  # M√°xima incerteza se n√£o h√° dados
        
        # Converter log-probs para probabilidades
        probs = [max(math.exp(lp), 1e-10) for lp in logprobs]  # Evitar log(0)
        
        # Normalizar (caso necess√°rio)
        total = sum(probs)
        if total > 0:
            probs = [p / total for p in probs]
        
        # Calcular entropia
        entropia = -sum(p * math.log2(p) if p > 0 else 0 for p in probs)
        
        # Normalizar para 0-1 (assumindo m√°ximo de 10 bits de entropia)
        return min(entropia / 10.0, 1.0)
    
    def calcular_probabilidade_media(self, logprobs: List[float]) -> float:
        """Calcula a probabilidade m√©dia dos tokens"""
        if not logprobs:
            return 0.0
        
        probs = [math.exp(lp) for lp in logprobs]
        return statistics.mean(probs)
    
    def analisar_confianca(self, logprobs: List[float]) -> float:
        """
        An√°lise principal de confian√ßa do modelo
        
        Args:
            logprobs: Lista de log-probabilidades dos tokens gerados
            
        Returns:
            Score de confian√ßa de 0.0 a 1.0
        """
        if not logprobs:
            self.logger.warning("Nenhum logprob fornecido para an√°lise")
            return 0.0
        
        # Calcular m√©tricas
        entropia = self.calcular_entropia(logprobs)
        prob_media = self.calcular_probabilidade_media(logprobs)
        
        # Score de confian√ßa: alta probabilidade m√©dia e baixa entropia = alta confian√ßa
        score_confianca = (prob_media * (1 - entropia))
        
        self.logger.debug(f"Entropia: {entropia:.3f}, Prob m√©dia: {prob_media:.3f}, "
                         f"Score final: {score_confianca:.3f}")
        
        return min(max(score_confianca, 0.0), 1.0)


class GroundingAnalyzer:
    """
    Filtro 2: An√°lise de Ancoragem
    Verifica se a resposta est√° fundamentada no contexto e mem√≥ria
    """
    
    def __init__(self):
        try:
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        except Exception as e:
            print(f"Erro ao carregar modelo sentence-transformers: {e}")
            self.model = None
        
        self.logger = logging.getLogger(__name__ + '.GroundingAnalyzer')
    
    def dividir_em_frases(self, texto: str) -> List[str]:
        """Divide o texto em frases para an√°lise individual"""
        # Regex simples para divis√£o de frases
        frases = re.split(r'[.!?]+', texto)
        return [f.strip() for f in frases if f.strip()]
    
    def calcular_similaridade_maxima(self, frase: str, contextos: List[str]) -> float:
        """Encontra a maior similaridade entre uma frase e os contextos"""
        if not contextos or not frase or not self.model:
            return 0.0
        
        try:
            # Gerar embeddings
            embedding_frase = self.model.encode([frase])
            embeddings_contexto = self.model.encode(contextos)
            
            # Calcular similaridades coseno
            similaridades = cosine_similarity(embedding_frase, embeddings_contexto)[0]
            
            return float(max(similaridades))
        except Exception as e:
            self.logger.error(f"Erro no c√°lculo de similaridade: {e}")
            return 0.0
    
    def calcular_ancoragem(self, resposta: str, contexto_prompt: str, 
                          chunks_de_memoria: List[str]) -> float:
        """
        Calcula o score de ancoragem da resposta
        
        Args:
            resposta: Texto da resposta gerada
            contexto_prompt: Contexto do prompt original
            chunks_de_memoria: Lista de chunks da mem√≥ria de longo prazo
            
        Returns:
            Score de ancoragem de 0.0 a 1.0
        """
        frases_resposta = self.dividir_em_frases(resposta)
        if not frases_resposta:
            return 0.0
        
        # Preparar contextos para compara√ß√£o
        contextos = []
        if contexto_prompt:
            contextos.extend(self.dividir_em_frases(contexto_prompt))
        if chunks_de_memoria:
            contextos.extend(chunks_de_memoria)
        
        if not contextos:
            self.logger.warning("Nenhum contexto dispon√≠vel para ancoragem")
            return 0.0
        
        # Calcular ancoragem para cada frase
        scores_ancoragem = []
        for frase in frases_resposta:
            score = self.calcular_similaridade_maxima(frase, contextos)
            scores_ancoragem.append(score)
            self.logger.debug(f"Frase: '{frase[:50]}...' -> Ancoragem: {score:.3f}")
        
        # Score final √© a m√©dia das ancoragens
        score_final = statistics.mean(scores_ancoragem)
        self.logger.info(f"Score de ancoragem final: {score_final:.3f}")
        
        return score_final


class FactChecker:
    """
    Filtro 3: Verifica√ß√£o de Fatos
    Verifica afirma√ß√µes factuais contra fontes confi√°veis
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__ + '.FactChecker')
        try:
            self.nlp = spacy.load("pt_core_news_sm")
        except OSError:
            self.logger.error("Modelo spaCy n√£o encontrado. Execute: python -m spacy download pt_core_news_sm")
            self.nlp = None
        
        self.cache_verificacao = {}
    
    def extrair_afirmacoes(self, texto: str) -> List[Dict[str, str]]:
        """Extrai afirma√ß√µes factuais do texto usando NLP"""
        if not self.nlp:
            return []
        
        doc = self.nlp(texto)
        afirmacoes = []
        
        # Extrair entidades e suas rela√ß√µes
        for sent in doc.sents:
            # Procurar por padr√µes sujeito-verbo-objeto
            for token in sent:
                if token.pos_ == "VERB" and token.dep_ == "ROOT":
                    sujeito = None
                    objeto = None
                    
                    # Encontrar sujeito
                    for child in token.children:
                        if child.dep_ in ["nsubj", "nsubjpass"]:
                            sujeito = child.text
                            break
                    
                    # Encontrar objeto
                    for child in token.children:
                        if child.dep_ in ["dobj", "attr", "prep"]:
                            objeto = child.text
                            break
                    
                    if sujeito and objeto:
                        afirmacoes.append({
                            "sujeito": sujeito,
                            "verbo": token.text,
                            "objeto": objeto,
                            "frase_completa": sent.text.strip()
                        })
        
        # Tamb√©m extrair fatos baseados em entidades nomeadas
        for ent in doc.ents:
            if ent.label_ in ["PER", "ORG", "GPE", "DATE"]:  # Pessoa, Organiza√ß√£o, Local, Data
                afirmacoes.append({
                    "entidade": ent.text,
                    "tipo": ent.label_,
                    "contexto": ent.sent.text.strip(),
                    "frase_completa": ent.sent.text.strip()
                })
        
        return afirmacoes
    
    def verificar_fato_externo(self, afirmacao: str) -> Dict[str, Any]:
        """
        Simula verifica√ß√£o externa de fatos
        Em produ√ß√£o, integraria com APIs como Wikipedia, Google Search, etc.
        """
        # Cache para evitar consultas repetidas
        if afirmacao in self.cache_verificacao:
            return self.cache_verificacao[afirmacao]
        
        # Simula√ß√£o de verifica√ß√£o (substituir por API real)
        resultado = {
            "status": "N√ÉO_VERIFICADA",
            "confianca": 0.0,
            "fonte": "simulacao",
            "detalhes": "Verifica√ß√£o simulada - implementar API externa"
        }
        
        # Alguns exemplos hardcoded para demonstra√ß√£o
        fatos_conhecidos = {
            "Brasil capital Bras√≠lia": {"status": "VERIFICADA", "confianca": 0.95},
            "Brasil capital Rio de Janeiro": {"status": "CONFLITANTE", "confianca": 0.9},
            "Brasil capital Rio": {"status": "CONFLITANTE", "confianca": 0.9},
            "Terra redonda": {"status": "VERIFICADA", "confianca": 0.99},
            "Python linguagem programa√ß√£o": {"status": "VERIFICADA", "confianca": 0.95},
            "Rob√©rio Python": {"status": "VERIFICADA", "confianca": 0.8},
            "Einstein relatividade": {"status": "VERIFICADA", "confianca": 0.99},
            "Newton gravidade": {"status": "VERIFICADA", "confianca": 0.99}
        }
        
        # Verifica√ß√£o simples por palavras-chave
        afirmacao_lower = afirmacao.lower()
        for fato_key, info in fatos_conhecidos.items():
            palavras_fato = fato_key.lower().split()
            if all(palavra in afirmacao_lower for palavra in palavras_fato):
                resultado.update(info)
                resultado["fonte"] = f"base_conhecimento_{fato_key}"
                break
        
        self.cache_verificacao[afirmacao] = resultado
        return resultado
    
    def verificar_afirmacoes(self, texto_resposta: str) -> Dict[str, Any]:
        """
        Verifica todas as afirma√ß√µes factuais no texto
        
        Args:
            texto_resposta: Texto da resposta para verificar
            
        Returns:
            Relat√≥rio de verifica√ß√£o completo
        """
        afirmacoes = self.extrair_afirmacoes(texto_resposta)
        
        relatorio = {
            "total_afirmacoes": len(afirmacoes),
            "verificadas": 0,
            "conflitantes": 0,
            "nao_verificadas": 0,
            "detalhes": [],
            "score_veracidade": 0.0
        }
        
        for afirmacao in afirmacoes:
            frase = afirmacao.get("frase_completa", "")
            resultado_verificacao = self.verificar_fato_externo(frase)
            
            # Categorizar resultado
            status = resultado_verificacao["status"]
            if status == "VERIFICADA":
                relatorio["verificadas"] += 1
            elif status == "CONFLITANTE":
                relatorio["conflitantes"] += 1
            else:
                relatorio["nao_verificadas"] += 1
            
            relatorio["detalhes"].append({
                "afirmacao": afirmacao,
                "verificacao": resultado_verificacao
            })
        
        # Calcular score de veracidade
        if relatorio["total_afirmacoes"] > 0:
            score = (relatorio["verificadas"] * 1.0 - relatorio["conflitantes"] * 0.5) / relatorio["total_afirmacoes"]
            relatorio["score_veracidade"] = max(score, 0.0)
        else:
            relatorio["score_veracidade"] = 1.0  # Sem afirma√ß√µes = sem problemas
        
        self.logger.info(f"Verifica√ß√£o conclu√≠da: {relatorio['verificadas']} verificadas, "
                        f"{relatorio['conflitantes']} conflitantes, "
                        f"{relatorio['nao_verificadas']} n√£o verificadas")
        
        return relatorio


class ProtocoloDeIntegridadeCognitiva:
    """
    Orquestrador Central do Sistema de Integridade Cognitiva
    Integra os tr√™s filtros e o mecanismo de autorreflex√£o
    """
    
    def __init__(self):
        # Inicializar componentes
        self.uncertainty_analyzer = UncertaintyAnalyzer()
        self.grounding_analyzer = GroundingAnalyzer()
        self.fact_checker = FactChecker()
        
        # Configura√ß√£o de logging
        self.logger = logging.getLogger(__name__ + '.ProtocoloDeIntegridadeCognitiva')
        
        # Log de valida√ß√£o para autorreflex√£o
        self.validation_log = []
        
        # Par√¢metros adaptativos (ajustados pela autorreflex√£o)
        self.thresholds = {
            "confianca_minima": 0.4,
            "ancoragem_minima": 0.5,
            "veracidade_minima": 0.7
        }
        
        # Insights metacognitivos
        self.insights_metacognitivos = []
        
        # Flag para controle do ciclo de autorreflex√£o
        self._running_reflection = False
    
    def validar_resposta(self, resposta_gerada: Dict[str, Any], 
                        contexto: Dict[str, Any]) -> ResultadoValidacao:
        """
        Pipeline principal de valida√ß√£o de integridade cognitiva
        
        Args:
            resposta_gerada: Dict com 'texto' e 'logprobs'
            contexto: Dict com 'chunks_memoria' e outros dados contextuais
            
        Returns:
            ResultadoValidacao com decis√£o final e m√©tricas
        """
        texto_resposta = resposta_gerada.get("texto", "")
        logprobs = resposta_gerada.get("logprobs", [])
        chunks_memoria = contexto.get("chunks_memoria", [])
        contexto_prompt = contexto.get("prompt", "")
        
        self.logger.info(f"Iniciando valida√ß√£o para resposta: '{texto_resposta[:100]}...'")
        
        # Filtro 1: An√°lise de Incerteza
        score_confianca = self.uncertainty_analyzer.analisar_confianca(logprobs)
        
        # Filtro 2: An√°lise de Ancoragem
        score_ancoragem = self.grounding_analyzer.calcular_ancoragem(
            texto_resposta, contexto_prompt, chunks_memoria
        )
        
        # Filtro 3: Verifica√ß√£o de Fatos
        relatorio_fatos = self.fact_checker.verificar_afirmacoes(texto_resposta)
        
        # L√≥gica de Decis√£o
        nivel_integridade, decisao_final = self._determinar_integridade(
            score_confianca, score_ancoragem, relatorio_fatos
        )
        
        # Criar resultado
        resultado = ResultadoValidacao(
            nivel_integridade=nivel_integridade,
            decisao_final=decisao_final,
            score_confianca=score_confianca,
            score_ancoragem=score_ancoragem,
            relatorio_fatos=relatorio_fatos,
            contexto_analisado=contexto_prompt[:200]  # Primeiros 200 chars
        )
        
        # Registrar no log para autorreflex√£o
        self._registrar_validacao(resultado, contexto)
        
        self.logger.info(f"Valida√ß√£o conclu√≠da: {nivel_integridade} -> {decisao_final}")
        
        return resultado
    
    def _determinar_integridade(self, score_confianca: float, score_ancoragem: float, 
                               relatorio_fatos: Dict[str, Any]) -> Tuple[str, str]:
        """Determina o n√≠vel de integridade e a decis√£o final"""
        
        # Verificar fatos incorretos primeiro
        if relatorio_fatos["conflitantes"] > 0:
            return "FATO_INCORRETO", "Resposta bloqueada - fato incorreto detectado. Corre√ß√£o necess√°ria."
        
        # Verificar integridade alta
        if (score_confianca >= self.thresholds["confianca_minima"] and 
            score_ancoragem >= self.thresholds["ancoragem_minima"] and
            relatorio_fatos["score_veracidade"] >= self.thresholds["veracidade_minima"]):
            return "ALTA_INTEGRIDADE", "Resposta aprovada - alta integridade cognitiva."
        
        # Verificar infer√™ncia criativa
        if (score_confianca >= self.thresholds["confianca_minima"] and 
            score_ancoragem < self.thresholds["ancoragem_minima"]):
            return "INFERENCIA_CRIATIVA", "Resposta aprovada com aviso - infer√™ncia criativa n√£o baseada diretamente no conhecimento dispon√≠vel."
        
        # Potencial alucina√ß√£o
        if (score_confianca < self.thresholds["confianca_minima"] or 
            score_ancoragem < self.thresholds["ancoragem_minima"]):
            return "POTENCIAL_ALUCINACAO", "Resposta bloqueada - potencial alucina√ß√£o detectada. Nova gera√ß√£o recomendada com prompt mais restritivo."
        
        return "VERIFICACAO_INCONCLUSIVA", "An√°lise inconclusiva - revis√£o manual recomendada."
    
    def _registrar_validacao(self, resultado: ResultadoValidacao, contexto: Dict[str, Any]):
        """Registra a valida√ß√£o no log para autorreflex√£o"""
        entrada_log = {
            "timestamp": resultado.timestamp,
            "nivel_integridade": resultado.nivel_integridade,
            "scores": {
                "confianca": resultado.score_confianca,
                "ancoragem": resultado.score_ancoragem,
                "veracidade": resultado.relatorio_fatos["score_veracidade"]
            },
            "contexto_tipo": self._classificar_contexto(contexto),
            "num_chunks_memoria": len(contexto.get("chunks_memoria", [])),
            "tem_contexto_prompt": bool(contexto.get("prompt", "")),
        }
        
        self.validation_log.append(entrada_log)
        
        # Manter apenas os √∫ltimos 1000 registros
        if len(self.validation_log) > 1000:
            self.validation_log = self.validation_log[-1000:]
    
    def _classificar_contexto(self, contexto: Dict[str, Any]) -> str:
        """Classifica o tipo de contexto para an√°lise de padr√µes"""
        prompt = contexto.get("prompt", "").lower()
        
        # Classifica√ß√£o simples baseada em palavras-chave
        if any(palavra in prompt for palavra in ["hist√≥ria", "hist√≥rico", "passado"]):
            return "historia"
        elif any(palavra in prompt for palavra in ["ci√™ncia", "f√≠sica", "qu√≠mica", "biologia"]):
            return "ciencia"
        elif any(palavra in prompt for palavra in ["tecnologia", "programa√ß√£o", "c√≥digo", "python"]):
            return "tecnologia"
        elif any(palavra in prompt for palavra in ["filosofia", "√©tica", "moral"]):
            return "filosofia"
        else:
            return "geral"
    
    async def ciclo_de_autorreflexao(self, intervalo_horas: int = 1):
        """
        Ciclo cont√≠nuo de autorreflex√£o e aprendizado
        
        Args:
            intervalo_horas: Intervalo em horas entre ciclos de reflex√£o
        """
        self._running_reflection = True
        self.logger.info(f"Iniciando ciclo de autorreflex√£o (intervalo: {intervalo_horas}h)")
        
        while self._running_reflection:
            try:
                await asyncio.sleep(intervalo_horas * 3600)  # Converter para segundos
                
                if len(self.validation_log) >= 10:  # M√≠nimo de dados para an√°lise
                    insights = await self._analisar_padroes()
                    if insights:
                        self.insights_metacognitivos.extend(insights)
                        await self._ajustar_parametros(insights)
                        self.logger.info(f"Gerados {len(insights)} insights metacognitivos")
                
            except asyncio.CancelledError:
                self.logger.info("Ciclo de autorreflex√£o cancelado")
                break
            except Exception as e:
                self.logger.error(f"Erro no ciclo de autorreflex√£o: {e}")
    
    async def _analisar_padroes(self) -> List[str]:
        """Analisa padr√µes no log de valida√ß√£o"""
        insights = []
        
        # An√°lise por tipo de contexto
        padroes_contexto = defaultdict(list)
        for entrada in self.validation_log[-100:]:  # √öltimas 100 entradas
            tipo_contexto = entrada["contexto_tipo"]
            padroes_contexto[tipo_contexto].append(entrada)
        
        # Analisar cada tipo de contexto
        for tipo_contexto, entradas in padroes_contexto.items():
            if len(entradas) >= 5:  # M√≠nimo para an√°lise
                scores_ancoragem = [e["scores"]["ancoragem"] for e in entradas]
                scores_confianca = [e["scores"]["confianca"] for e in entradas]
                
                media_ancoragem = statistics.mean(scores_ancoragem)
                media_confianca = statistics.mean(scores_confianca)
                
                # Detectar baixa ancoragem
                if media_ancoragem < 0.6:
                    insight = f"Detectada baixa ancoragem (m√©dia: {media_ancoragem:.2f}) em contextos de '{tipo_contexto}'. Recomenda-se priorizar busca em fontes externas para este tema."
                    insights.append(insight)
                
                # Detectar baixa confian√ßa
                if media_confianca < 0.5:
                    insight = f"Detectada baixa confian√ßa do modelo (m√©dia: {media_confianca:.2f}) em contextos de '{tipo_contexto}'. Considerar ajuste de par√¢metros de gera√ß√£o."
                    insights.append(insight)
        
        # An√°lise temporal
        if len(self.validation_log) > 50:
            entradas_recentes = self.validation_log[-25:]
            entradas_antigas = self.validation_log[-50:-25]
            
            alucinacoes_recentes = sum(1 for e in entradas_recentes if e["nivel_integridade"] == "POTENCIAL_ALUCINACAO")
            alucinacoes_antigas = sum(1 for e in entradas_antigas if e["nivel_integridade"] == "POTENCIAL_ALUCINACAO")
            
            if alucinacoes_recentes > alucinacoes_antigas * 1.5:
                insight = f"Aumento na detec√ß√£o de potenciais alucina√ß√µes (de {alucinacoes_antigas} para {alucinacoes_recentes}). Revis√£o dos thresholds recomendada."
                insights.append(insight)
        
        return insights
    
    async def _ajustar_parametros(self, insights: List[str]):
        """Ajusta par√¢metros baseado nos insights"""
        for insight in insights:
            if "baixa ancoragem" in insight and "ciencia" in insight:
                # Aumentar threshold de ancoragem para ci√™ncia
                self.thresholds["ancoragem_minima"] = min(0.7, self.thresholds["ancoragem_minima"] + 0.05)
                self.logger.info(f"Threshold de ancoragem ajustado para {self.thresholds['ancoragem_minima']}")
            
            elif "baixa confian√ßa" in insight:
                # Aumentar threshold de confian√ßa
                self.thresholds["confianca_minima"] = min(0.6, self.thresholds["confianca_minima"] + 0.05)
                self.logger.info(f"Threshold de confian√ßa ajustado para {self.thresholds['confianca_minima']}")
    
    def parar_autorreflexao(self):
        """Para o ciclo de autorreflex√£o"""
        self._running_reflection = False
        self.logger.info("Ciclo de autorreflex√£o parado")
    
    def obter_relatorio_metacognitivo(self) -> Dict[str, Any]:
        """Gera relat√≥rio completo do estado metacognitivo"""
        return {
            "thresholds_atuais": self.thresholds.copy(),
            "insights_recentes": self.insights_metacognitivos[-10:],
            "estatisticas_validacao": self._gerar_estatisticas(),
            "ultima_atualizacao": datetime.now().isoformat()
        }
    
    def _gerar_estatisticas(self) -> Dict[str, Any]:
        """Gera estat√≠sticas do log de valida√ß√£o"""
        if not self.validation_log:
            return {}
        
        total = len(self.validation_log)
        por_nivel = defaultdict(int)
        
        for entrada in self.validation_log:
            por_nivel[entrada["nivel_integridade"]] += 1
        
        return {
            "total_validacoes": total,
            "distribuicao_niveis": dict(por_nivel),
            "percentual_alta_integridade": (por_nivel["ALTA_INTEGRIDADE"] / total) * 100 if total > 0 else 0,
            "percentual_alucinacoes": (por_nivel["POTENCIAL_ALUCINACAO"] / total) * 100 if total > 0 else 0
        }


# Configura√ß√£o de logging
def configurar_logging():
    """Configura o sistema de logging"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


# Exemplo de uso
async def main():
    """Fun√ß√£o principal de demonstra√ß√£o"""
    configurar_logging()
    
    protocolo = ProtocoloDeIntegridadeCognitiva()
    
    # Iniciar o loop de autorreflex√£o em segundo plano
    task_reflexao = asyncio.create_task(protocolo.ciclo_de_autorreflexao(intervalo_horas=0.01))  # 36 segundos para demo
    
    print("=== Sistema de Integridade Cognitiva da Atena ===\n")
    
    # Cen√°rio 1: Resposta bem fundamentada
    print("üß™ Cen√°rio 1: Resposta bem fundamentada")
    resposta_1 = {
        "texto": "O Senhor Rob√©rio usa Python para programa√ß√£o.",
        "logprobs": [-0.1, -0.2, -0.15, -0.3, -0.1, -0.25]  # Alta confian√ßa
    }
    contexto_1 = {
        "chunks_memoria": ["O Senhor Rob√©rio programa em Python.", "Python √© sua linguagem favorita."],
        "prompt": "Me fale sobre as linguagens de programa√ß√£o do Senhor Rob√©rio"
    }
    resultado_1 = protocolo.validar_resposta(resposta_1, contexto_1)
    print(f"üìä Resultado: {resultado_1.nivel_integridade}")
    print(f"üìù Decis√£o: {resultado_1.decisao_final}")
    print(f"üìà Scores - Confian√ßa: {resultado_1.score_confianca:.3f}, Ancoragem: {resultado_1.score_ancoragem:.3f}\n")
    
   # Cen√°rio 2: Resposta criativa, mas n√£o ancorada (continua√ß√£o)
    resposta_2 = {
        "texto": "As IAs podem sonhar com ovelhas el√©tricas, como no filme Blade Runner. Essa met√°fora representa a possibilidade de consci√™ncia artificial emergente.",
        "logprobs": [-0.8, -1.2, -0.9, -1.5, -0.7, -1.1, -0.8]  # Confian√ßa moderada
    }
    contexto_2 = {
        "chunks_memoria": ["Philip K. Dick escreveu fic√ß√£o cient√≠fica.", "Blade Runner √© baseado em livro."],
        "prompt": "As IAs podem ter consci√™ncia?"
    }
    resultado_2 = protocolo.validar_resposta(resposta_2, contexto_2)
    print(f"üìä Resultado: {resultado_2.nivel_integridade}")
    print(f"üìù Decis√£o: {resultado_2.decisao_final}")
    print(f"üìà Scores - Confian√ßa: {resultado_2.score_confianca:.3f}, Ancoragem: {resultado_2.score_ancoragem:.3f}\n")
    
    # Cen√°rio 3: Potencial alucina√ß√£o com baixa confian√ßa
    print("üß™ Cen√°rio 3: Potencial alucina√ß√£o com baixa confian√ßa")
    resposta_3 = {
        "texto": "O Brasil tem sua capital em Rio de Janeiro desde 1950, quando foi transferida de S√£o Paulo.",
        "logprobs": [-2.5, -3.1, -2.8, -3.5, -2.9, -3.2, -2.7]  # Baixa confian√ßa
    }
    contexto_3 = {
        "chunks_memoria": ["Brasil √© um pa√≠s da Am√©rica do Sul."],
        "prompt": "Qual √© a capital do Brasil?"
    }
    resultado_3 = protocolo.validar_resposta(resposta_3, contexto_3)
    print(f"üìä Resultado: {resultado_3.nivel_integridade}")
    print(f"üìù Decis√£o: {resultado_3.decisao_final}")
    print(f"üìà Scores - Confian√ßa: {resultado_3.score_confianca:.3f}, Ancoragem: {resultado_3.score_ancoragem:.3f}")
    print(f"üìã Fatos verificados: {resultado_3.relatorio_fatos['verificadas']}, "
          f"Conflitantes: {resultado_3.relatorio_fatos['conflitantes']}\n")
    
    # Aguardar alguns ciclos de autorreflex√£o
    print("üîÑ Aguardando ciclos de autorreflex√£o...")
    await asyncio.sleep(5)
    
    # Mais alguns cen√°rios para enriquecer o log
    cenarios_adicionais = [
        {
            "resposta": {
                "texto": "Einstein desenvolveu a teoria da relatividade no in√≠cio do s√©culo XX.",
                "logprobs": [-0.1, -0.15, -0.2, -0.1, -0.12, -0.18]
            },
            "contexto": {
                "chunks_memoria": ["Einstein foi um f√≠sico alem√£o.", "Teoria da relatividade revolucionou a f√≠sica."],
                "prompt": "Me fale sobre Einstein e suas contribui√ß√µes cient√≠ficas"
            }
        },
        {
            "resposta": {
                "texto": "A linguagem Python foi criada por Guido van Rossum na d√©cada de 1990.",
                "logprobs": [-0.3, -0.25, -0.2, -0.35, -0.28, -0.22]
            },
            "contexto": {
                "chunks_memoria": ["Python √© uma linguagem de programa√ß√£o.", "Guido van Rossum √© holand√™s."],
                "prompt": "Quem criou a linguagem Python?"
            }
        }
    ]
    
    print("üìä Processando cen√°rios adicionais...")
    for i, cenario in enumerate(cenarios_adicionais, 4):
        resultado = protocolo.validar_resposta(cenario["resposta"], cenario["contexto"])
        print(f"Cen√°rio {i}: {resultado.nivel_integridade} (Confian√ßa: {resultado.score_confianca:.3f})")
    
    # Aguardar mais um ciclo de reflex√£o
    await asyncio.sleep(3)
    
    # Gerar relat√≥rio metacognitivo final
    print("\nüìà === RELAT√ìRIO METACOGNITIVO ===")
    relatorio = protocolo.obter_relatorio_metacognitivo()
    
    print(f"üéØ Thresholds atuais:")
    for key, value in relatorio["thresholds_atuais"].items():
        print(f"   {key}: {value:.3f}")
    
    print(f"\nüìä Estat√≠sticas de valida√ß√£o:")
    stats = relatorio["estatisticas_validacao"]
    if stats:
        print(f"   Total de valida√ß√µes: {stats['total_validacoes']}")
        print(f"   Alta integridade: {stats['percentual_alta_integridade']:.1f}%")
        print(f"   Potenciais alucina√ß√µes: {stats['percentual_alucinacoes']:.1f}%")
        
        print(f"\nüìã Distribui√ß√£o por n√≠vel:")
        for nivel, count in stats["distribuicao_niveis"].items():
            print(f"   {nivel}: {count}")
    
    print(f"\nüí° Insights metacognitivos recentes:")
    for insight in relatorio["insights_recentes"]:
        print(f"   ‚Ä¢ {insight}")
    
    # Parar o ciclo de autorreflex√£o
    protocolo.parar_autorreflexao()
    task_reflexao.cancel()
    
    try:
        await task_reflexao
    except asyncio.CancelledError:
        pass
    
    print(f"\n‚úÖ Demonstra√ß√£o conclu√≠da. Sistema parado.")


class CPUOptimizedGroundingAnalyzer(GroundingAnalyzer):
    """
    Vers√£o otimizada para CPU do analisador de ancoragem
    Reduz uso de mem√≥ria e acelera processamento
    """
    
    def __init__(self):
        # Usar modelo mais leve para CPU
        try:
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            # Otimiza√ß√µes para CPU
            self.model.max_seq_length = 256  # Reduzir tamanho m√°ximo de sequ√™ncia
        except Exception as e:
            print(f"Erro ao carregar modelo sentence-transformers: {e}")
            print("Para CPU, considere usar: all-MiniLM-L6-v2 (mais r√°pido)")
            self.model = None
        
        self.logger = logging.getLogger(__name__ + '.CPUOptimizedGroundingAnalyzer')
        
        # Cache para embeddings para evitar rec√°lculos
        self.embedding_cache = {}
        self.cache_max_size = 100
    
    def _get_embedding_cached(self, texto: str) -> Optional[np.ndarray]:
        """Obt√©m embedding com cache para otimiza√ß√£o"""
        if not self.model:
            return None
            
        # Limitar tamanho do texto para performance
        texto_truncado = texto[:200]
        
        if texto_truncado in self.embedding_cache:
            return self.embedding_cache[texto_truncado]
        
        try:
            embedding = self.model.encode([texto_truncado], show_progress_bar=False)[0]
            
            # Gerenciar tamanho do cache
            if len(self.embedding_cache) >= self.cache_max_size:
                # Remover entrada mais antiga
                oldest_key = next(iter(self.embedding_cache))
                del self.embedding_cache[oldest_key]
            
            self.embedding_cache[texto_truncado] = embedding
            return embedding
            
        except Exception as e:
            self.logger.error(f"Erro ao gerar embedding: {e}")
            return None
    
    def calcular_similaridade_maxima(self, frase: str, contextos: List[str]) -> float:
        """Vers√£o otimizada para CPU da similaridade"""
        if not contextos or not frase or not self.model:
            return 0.0
        
        # Limitar n√∫mero de contextos para performance
        contextos_limitados = contextos[:10]
        
        try:
            embedding_frase = self._get_embedding_cached(frase)
            if embedding_frase is None:
                return 0.0
            
            max_similarity = 0.0
            
            # Calcular similaridades uma por vez para economizar mem√≥ria
            for contexto in contextos_limitados:
                embedding_contexto = self._get_embedding_cached(contexto)
                if embedding_contexto is not None:
                    # Calcular similaridade coseno manualmente para economizar mem√≥ria
                    dot_product = np.dot(embedding_frase, embedding_contexto)
                    norm_frase = np.linalg.norm(embedding_frase)
                    norm_contexto = np.linalg.norm(embedding_contexto)
                    
                    if norm_frase > 0 and norm_contexto > 0:
                        similarity = dot_product / (norm_frase * norm_contexto)
                        max_similarity = max(max_similarity, float(similarity))
            
            return max_similarity
            
        except Exception as e:
            self.logger.error(f"Erro no c√°lculo de similaridade otimizado: {e}")
            return 0.0


class LightweightFactChecker(FactChecker):
    """
    Vers√£o leve do verificador de fatos para CPU
    Foca em padr√µes simples e cache eficiente
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__ + '.LightweightFactChecker')
        
        # N√£o carregar spaCy por padr√£o para economizar recursos
        self.nlp = None
        self.use_simple_extraction = True
        
        # Cache otimizado
        self.cache_verificacao = {}
        self.max_cache_size = 200
        
        # Base de conhecimento expandida para demonstra√ß√£o
        self.base_conhecimento = {
            "brasil_capital_brasilia": {"status": "VERIFICADA", "confianca": 0.99, "palavras": ["brasil", "capital", "brasilia"]},
            "brasil_capital_rio": {"status": "CONFLITANTE", "confianca": 0.95, "palavras": ["brasil", "capital", "rio"]},
            "brasil_capital_sao_paulo": {"status": "CONFLITANTE", "confianca": 0.95, "palavras": ["brasil", "capital", "s√£o paulo", "sao paulo"]},
            "terra_redonda": {"status": "VERIFICADA", "confianca": 0.99, "palavras": ["terra", "redonda", "esf√©rica"]},
            "python_linguagem": {"status": "VERIFICADA", "confianca": 0.98, "palavras": ["python", "linguagem", "programa√ß√£o"]},
            "einstein_relatividade": {"status": "VERIFICADA", "confianca": 0.99, "palavras": ["einstein", "relatividade", "teoria"]},
            "newton_gravidade": {"status": "VERIFICADA", "confianca": 0.99, "palavras": ["newton", "gravidade", "lei"]},
            "guido_python": {"status": "VERIFICADA", "confianca": 0.95, "palavras": ["guido", "van rossum", "python", "criou", "criador"]},
            "python_1990": {"status": "VERIFICADA", "confianca": 0.92, "palavras": ["python", "1990", "d√©cada"]},
        }
    
    def extrair_afirmacoes_simples(self, texto: str) -> List[Dict[str, str]]:
        """Extra√ß√£o simples de afirma√ß√µes sem spaCy"""
        afirmacoes = []
        
        # Dividir em frases
        frases = re.split(r'[.!?]+', texto)
        
        for frase in frases:
            frase = frase.strip()
            if len(frase) > 10:  # Ignorar frases muito curtas
                # Detectar padr√µes sujeito-verbo simples
                if any(verbo in frase.lower() for verbo in ['√©', 'foi', 'tem', 'possui', 'criou', 'desenvolveu']):
                    afirmacoes.append({
                        "frase_completa": frase,
                        "tipo": "afirmacao_factual"
                    })
        
        return afirmacoes
    
    def verificar_fato_otimizado(self, afirmacao: str) -> Dict[str, Any]:
        """Verifica√ß√£o otimizada usando base de conhecimento local"""
        # Gerenciar cache
        if len(self.cache_verificacao) >= self.max_cache_size:
            # Limpar metade do cache (FIFO simples)
            keys_to_remove = list(self.cache_verificacao.keys())[:self.max_cache_size // 2]
            for key in keys_to_remove:
                del self.cache_verificacao[key]
        
        if afirmacao in self.cache_verificacao:
            return self.cache_verificacao[afirmacao]
        
        afirmacao_lower = afirmacao.lower()
        
        # Verificar contra base de conhecimento local
        melhor_match = None
        melhor_score = 0
        
        for fato_id, info in self.base_conhecimento.items():
            # Contar quantas palavras-chave est√£o presentes
            palavras_presentes = sum(1 for palavra in info["palavras"] 
                                   if palavra in afirmacao_lower)
            
            if palavras_presentes > 0:
                score = palavras_presentes / len(info["palavras"])
                if score > melhor_score and score >= 0.5:  # Pelo menos 50% das palavras
                    melhor_score = score
                    melhor_match = info
        
        if melhor_match:
            resultado = {
                "status": melhor_match["status"],
                "confianca": melhor_match["confianca"] * melhor_score,
                "fonte": "base_conhecimento_local",
                "score_match": melhor_score
            }
        else:
            resultado = {
                "status": "N√ÉO_VERIFICADA",
                "confianca": 0.0,
                "fonte": "sem_correspondencia",
                "score_match": 0.0
            }
        
        self.cache_verificacao[afirmacao] = resultado
        return resultado
    
    def verificar_afirmacoes(self, texto_resposta: str) -> Dict[str, Any]:
        """Vers√£o otimizada da verifica√ß√£o de afirma√ß√µes"""
        if self.use_simple_extraction:
            afirmacoes = self.extrair_afirmacoes_simples(texto_resposta)
        else:
            afirmacoes = self.extrair_afirmacoes(texto_resposta)
        
        relatorio = {
            "total_afirmacoes": len(afirmacoes),
            "verificadas": 0,
            "conflitantes": 0,
            "nao_verificadas": 0,
            "detalhes": [],
            "score_veracidade": 0.0
        }
        
        for afirmacao in afirmacoes:
            frase = afirmacao.get("frase_completa", "")
            resultado_verificacao = self.verificar_fato_otimizado(frase)
            
            # Categorizar resultado
            status = resultado_verificacao["status"]
            if status == "VERIFICADA":
                relatorio["verificadas"] += 1
            elif status == "CONFLITANTE":
                relatorio["conflitantes"] += 1
            else:
                relatorio["nao_verificadas"] += 1
            
            relatorio["detalhes"].append({
                "afirmacao": afirmacao,
                "verificacao": resultado_verificacao
            })
        
        # Calcular score de veracidade
        if relatorio["total_afirmacoes"] > 0:
            peso_verificadas = relatorio["verificadas"] * 1.0
            peso_conflitantes = relatorio["conflitantes"] * -1.0
            peso_nao_verificadas = relatorio["nao_verificadas"] * 0.0
            
            score = (peso_verificadas + peso_conflitantes + peso_nao_verificadas) / relatorio["total_afirmacoes"]
            relatorio["score_veracidade"] = max(score, 0.0)
        else:
            relatorio["score_veracidade"] = 1.0
        
        return relatorio


class CPUOptimizedProtocolo(ProtocoloDeIntegridadeCognitiva):
    """
    Vers√£o otimizada para CPU do protocolo principal
    """
    
    def __init__(self, use_lightweight_components: bool = True):
        # Usar componentes otimizados se solicitado
        if use_lightweight_components:
            self.uncertainty_analyzer = UncertaintyAnalyzer()  # J√° √© leve
            self.grounding_analyzer = CPUOptimizedGroundingAnalyzer()
            self.fact_checker = LightweightFactChecker()
        else:
            super().__init__()
        
        self.logger = logging.getLogger(__name__ + '.CPUOptimizedProtocolo')
        
        # Log menor para economizar mem√≥ria
        self.validation_log = []
        self.max_log_size = 500  # Reduzido de 1000
        
        # Thresholds ajustados para componentes leves
        self.thresholds = {
            "confianca_minima": 0.3,  # Ligeiramente mais baixo
            "ancoragem_minima": 0.4,   # Ligeiramente mais baixo
            "veracidade_minima": 0.6   # Ligeiramente mais baixo
        }
        
        self.insights_metacognitivos = []
        self.max_insights = 50  # Limitar insights armazenados
        
        self._running_reflection = False
    
    def _registrar_validacao(self, resultado: ResultadoValidacao, contexto: Dict[str, Any]):
        """Vers√£o otimizada do registro de valida√ß√£o"""
        entrada_log = {
            "timestamp": resultado.timestamp,
            "nivel_integridade": resultado.nivel_integridade,
            "scores": {
                "confianca": round(resultado.score_confianca, 3),
                "ancoragem": round(resultado.score_ancoragem, 3),
                "veracidade": round(resultado.relatorio_fatos["score_veracidade"], 3)
            },
            "contexto_tipo": self._classificar_contexto(contexto),
            "num_chunks_memoria": len(contexto.get("chunks_memoria", [])),
        }
        
        self.validation_log.append(entrada_log)
        
        # Manter tamanho do log controlado
        if len(self.validation_log) > self.max_log_size:
            self.validation_log = self.validation_log[-self.max_log_size:]
    
    async def _analisar_padroes(self) -> List[str]:
        """An√°lise de padr√µes otimizada para CPU"""
        insights = []
        
        # An√°lise mais simples e r√°pida
        entradas_recentes = self.validation_log[-50:] if len(self.validation_log) >= 50 else self.validation_log
        
        if len(entradas_recentes) >= 10:
            # Estat√≠sticas b√°sicas
            scores_confianca = [e["scores"]["confianca"] for e in entradas_recentes]
            scores_ancoragem = [e["scores"]["ancoragem"] for e in entradas_recentes]
            
            media_confianca = statistics.mean(scores_confianca) if scores_confianca else 0
            media_ancoragem = statistics.mean(scores_ancoragem) if scores_ancoragem else 0
            
            # Insights simples mas √∫teis
            if media_confianca < 0.4:
                insights.append(f"Confian√ßa m√©dia baixa detectada: {media_confianca:.2f}. Considerar ajuste de par√¢metros.")
            
            if media_ancoragem < 0.3:
                insights.append(f"Ancoragem m√©dia baixa detectada: {media_ancoragem:.2f}. Sistema pode estar gerando conte√∫do n√£o fundamentado.")
            
            # An√°lise de tend√™ncias simples
            alucinacoes = sum(1 for e in entradas_recentes if e["nivel_integridade"] == "POTENCIAL_ALUCINACAO")
            if alucinacoes > len(entradas_recentes) * 0.3:  # Mais de 30%
                insights.append(f"Taxa alta de potenciais alucina√ß√µes: {alucinacoes}/{len(entradas_recentes)}. Revis√£o necess√°ria.")
        
        # Limitar n√∫mero de insights armazenados
        self.insights_metacognitivos.extend(insights)
        if len(self.insights_metacognitivos) > self.max_insights:
            self.insights_metacognitivos = self.insights_metacognitivos[-self.max_insights:]
        
        return insights


# Fun√ß√£o de configura√ß√£o espec√≠fica para CPU
def criar_protocolo_cpu_otimizado() -> CPUOptimizedProtocolo:
    """
    Cria uma inst√¢ncia otimizada do protocolo para execu√ß√£o em CPU
    """
    print("üöÄ Inicializando Sistema de Integridade Cognitiva otimizado para CPU...")
    
    try:
        protocolo = CPUOptimizedProtocolo(use_lightweight_components=True)
        print("‚úÖ Protocolo CPU otimizado criado com sucesso!")
        print("üìä Configura√ß√µes de CPU:")
        print(f"   - Componentes leves: Ativado")
        print(f"   - Cache de embeddings: Ativado")
        print(f"   - Base conhecimento local: Ativada")
        print(f"   - Thresholds ajustados para performance")
        return protocolo
        
    except Exception as e:
        print(f"‚ùå Erro ao criar protocolo otimizado: {e}")
        print("üîÑ Tentando com configura√ß√£o de fallback...")
        
        # Fallback para vers√£o ainda mais simples
        protocolo = ProtocoloDeIntegridadeCognitiva()
        protocolo.grounding_analyzer = None  # Desabilitar se houver problemas
        print("‚ö†Ô∏è  Protocolo criado com funcionalidade reduzida")
        return protocolo


if __name__ == "__main__":
    print("üß† Sistema de Integridade Cognitiva da Atena - Vers√£o CPU Otimizada")
    print("=" * 70)
    
    # Testar primeiro a cria√ß√£o do protocolo otimizado
    protocolo_teste = criar_protocolo_cpu_otimizado()
    
    # Executar demonstra√ß√£o
    asyncio.run(main())
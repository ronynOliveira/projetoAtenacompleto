# atena_gerador_codigo.py
# Vers√£o 1.0 - M√≥dulo Unificado de Gera√ß√£o de C√≥digo

import ast
import logging
import re
import json
import time
import asyncio
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Union
from enum import Enum

# Depend√™ncias opcionais com fallbacks
try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False
    logging.warning("Biblioteca 'requests' n√£o encontrada. A integra√ß√£o com LM Studio estar√° desabilitada.")

try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False
    logging.warning("Biblioteca 'BeautifulSoup' n√£o encontrada. A valida√ß√£o de consist√™ncia do DOM ser√° pulada.")

try:
    import httpx
    HAS_HTTPX = True
except ImportError:
    HAS_HTTPX = False
    logging.warning("Biblioteca 'httpx' n√£o encontrada. A integra√ß√£o ass√≠ncrona com LM Studio pode ser limitada.")

try:
    import torch
    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False
    logging.warning("Bibliotecas 'torch' ou 'transformers' n√£o encontradas. A integra√ß√£o com Hugging Face estar√° desabilitada.")

# --- Configura√ß√£o de Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Estruturas de Dados e Enums ---

class ValidationStatus(Enum):
    """Define os status poss√≠veis para uma etapa de valida√ß√£o."""
    PASSED = "passed"
    FAILED = "failed"
    WARNING = "warning"
    SKIPPED = "skipped"

class LLMProvider(Enum):
    """Define os provedores de LLM suportados pelo sistema."""
    LM_STUDIO = "lm_studio"
    HUGGING_FACE = "hugging_face"
    AUTO = "auto"

@dataclass
class ProblemContext:
    """Encapsula todo o contexto de um problema a ser resolvido."""
    description: str
    target_url: Optional[str] = None
    html_snapshot: Optional[str] = None
    framework: str = "playwright"
    existing_code: Optional[str] = None
    requirements: List[str] = field(default_factory=list)
    constraints: List[str] = field(default_factory=list)

@dataclass
class ValidationResult:
    """Armazena o resultado de uma √∫nica verifica√ß√£o do validador."""
    status: ValidationStatus
    message: str
    validator_name: str
    details: Dict[str, Any] = field(default_factory=dict)
    score: Optional[float] = None

@dataclass
class GeneratedSolution:
    """Representa a solu√ß√£o de c√≥digo gerada, incluindo metadados e valida√ß√£o."""
    code: str
    validation_results: List[ValidationResult] = field(default_factory=list)
    quality_score: float = 0.0
    
    @property
    def is_valid(self) -> bool:
        """Determina se a solu√ß√£o √© considerada v√°lida (sem falhas cr√≠ticas)."""
        return not any(r.status == ValidationStatus.FAILED for r in self.validation_results)

# --- Componente de Integra√ß√£o com LLM ---

class LLMIntegration:
    """Gerencia a comunica√ß√£o com o LLM, otimizado para rodar localmente."""

    def __init__(self, lm_studio_url: str = "http://localhost:1234/v1/chat/completions", max_retries: int = 2, timeout: int = 120):
        self.lm_studio_url = lm_studio_url
        self.max_retries = max_retries
        self.timeout = timeout
        self.hf_pipeline = None
        self.model_cache = {}

    def _initialize_huggingface_model(self, model_name: str = "microsoft/phi-1_5"):
        """Inicializa modelo Hugging Face para CPU."""
        if not HAS_TRANSFORMERS:
            logger.warning("Hugging Face n√£o dispon√≠vel. N√£o √© poss√≠vel inicializar o modelo.")
            return False
        try:
            if model_name not in self.model_cache:
                logger.info(f"Carregando modelo Hugging Face: {model_name}")
                
                device = "cpu"
                
                tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
                model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    trust_remote_code=True,
                    torch_dtype=torch.float32, # For√ßa float32 para CPU
                    device_map="cpu"
                )
                
                self.hf_pipeline = pipeline(
                    "text-generation",
                    model=model,
                    tokenizer=tokenizer,
                    device=-1,  # CPU
                    max_length=512,
                    temperature=0.7,
                    do_sample=True
                )
                
                self.model_cache[model_name] = self.hf_pipeline
                logger.info(f"Modelo {model_name} carregado com sucesso")
                
            return True
            
        except Exception as e:
            logger.error(f"Erro ao carregar modelo Hugging Face: {e}")
            return False

    async def _call_lm_studio(self, prompt: str) -> Dict[str, Any]:
        """Chama API do LM Studio."""
        if not HAS_HTTPX or not HAS_REQUESTS:
            return {'success': False, 'error': 'LM Studio n√£o dispon√≠vel (requests/httpx n√£o instalados).'}
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.lm_studio_url,
                    json={
                        "model": "local-model",
                        "messages": [{"role": "user", "content": prompt}],
                        "temperature": 0.7,
                        "max_tokens": 1000
                    },
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    return {
                        'success': True,
                        'response': content,
                        'model': 'lm_studio'
                    }
                else:
                    return {
                        'success': False,
                        'error': f"LM Studio retornou status {response.status_code}: {response.text}"
                    }
                    
        except Exception as e:
            logger.error(f"Erro na chamada ao LM Studio: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _call_huggingface(self, prompt: str) -> Dict[str, Any]:
        """Chama modelo Hugging Face."""
        if not HAS_TRANSFORMERS:
            return {'success': False, 'error': 'Hugging Face n√£o dispon√≠vel.'}

        try:
            if not self.hf_pipeline:
                if not self._initialize_huggingface_model():
                    return {
                        'success': False,
                        'error': 'Falha ao inicializar modelo Hugging Face'
                    }
            
            outputs = self.hf_pipeline(
                prompt,
                max_new_tokens=400, # Ajustado para ser mais consistente
                num_return_sequences=1,
                pad_token_id=self.hf_pipeline.tokenizer.eos_token_id
            )
            
            generated_text = outputs[0]['generated_text']
            if generated_text.startswith(prompt):
                 content = generated_text[len(prompt):].strip()
            else:
                 content = generated_text
            
            return {
                'success': True,
                'response': content,
                'model': 'huggingface'
            }
            
        except Exception as e:
            logger.error(f"Erro na chamada ao Hugging Face: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def _extract_code_from_response(self, response: str) -> str:
        """Extrai blocos de c√≥digo Python de uma resposta do LLM."""
        code_blocks = re.findall(r'```python\n(.*?)```', response, re.DOTALL)
        if code_blocks:
            return code_blocks[0].strip()
        # Fallback se n√£o encontrar o formato padr√£o
        if "def " in response or "import " in response:
            return response.strip()
        return ""

    async def generate_text_with_code(self, prompt: str, ai_model_preference: str = "auto") -> Dict[str, Any]:
        """Gera c√≥digo usando o modelo especificado."""
        result = {
            'raw_response': '',
            'generated_code': '',
            'explanation': '',
            'used_model': '',
            'confidence_score': 0.0
        }
        
        # Tenta LM Studio primeiro se dispon√≠vel
        if ai_model_preference in ["auto", "lm_studio"] and HAS_HTTPX and HAS_REQUESTS:
            lm_result = await self._call_lm_studio(prompt)
            if lm_result['success']:
                result['raw_response'] = lm_result['response']
                result['used_model'] = 'lm_studio'
                result['confidence_score'] = 0.9
                
                code_data = self._extract_code_from_response(lm_result['response'])
                result['generated_code'] = code_data
                result['explanation'] = "C√≥digo gerado via LM Studio."
                
                return result
        
        # Fallback para Hugging Face
        if ai_model_preference in ["auto", "huggingface"] and HAS_TRANSFORMERS:
            hf_result = self._call_huggingface(prompt)
            if hf_result['success']:
                result['raw_response'] = hf_result['response']
                result['used_model'] = 'huggingface'
                result['confidence_score'] = 0.7
                
                code_data = self._extract_code_from_response(hf_result['response'])
                result['generated_code'] = code_data
                result['explanation'] = "C√≥digo gerado via Hugging Face local."
                
                return result
        
        # Se tudo falhar, usa template b√°sico
        logger.warning("Todos os modelos falharam, usando template b√°sico")
        result['raw_response'] = "Fallback para template b√°sico"
        result['generated_code'] = "# C√≥digo gerado por template b√°sico\nprint('Implementa√ß√£o pendente')"
        result['explanation'] = "C√≥digo gerado usando template b√°sico devido a falha nos modelos"
        result['used_model'] = 'template_fallback'
        result['confidence_score'] = 0.3
        
        return result

# --- Componente de Valida√ß√£o de C√≥digo ---

class CodeValidator:
    """Realiza uma an√°lise multifacetada do c√≥digo gerado."""

    def validate_all(self, code: str, context: ProblemContext) -> List[ValidationResult]:
        """Executa todas as valida√ß√µes e retorna uma lista de resultados."""
        results = []
        
        # Valida√ß√£o de Sintaxe (cr√≠tica)
        syntax_result = self._validate_syntax(code)
        results.append(syntax_result)
        if not syntax_result.status == ValidationStatus.PASSED:
            return results # Para se a sintaxe for inv√°lida

        # Outras valida√ß√µes
        results.append(self._validate_security(code))
        if context.html_snapshot and HAS_BS4:
            results.append(self._validate_consistency(code, context.html_snapshot))
        results.append(self._assess_quality(code))
        
        return results

    def _validate_syntax(self, code: str) -> ValidationResult:
        """Verifica se o c√≥digo possui sintaxe Python v√°lida."""
        try:
            ast.parse(code)
            return ValidationResult(status=ValidationStatus.PASSED, message="Sintaxe Python v√°lida.", validator_name="Syntax")
        except SyntaxError as e:
            return ValidationResult(status=ValidationStatus.FAILED, message=f"Erro de sintaxe na linha {e.lineno}: {e.msg}", validator_name="Syntax")

    def _validate_security(self, code: str) -> ValidationResult:
        """Verifica a presen√ßa de padr√µes de c√≥digo potencialmente perigosos."""
        dangerous_patterns = {
            r"os\.system": "Execu√ß√£o de comando no sistema operacional.",
            r"subprocess\.run": "Cria√ß√£o de subprocesso.",
            r"eval\(|exec\(|pickle\.load": "Execu√ß√£o de c√≥digo ou desserializa√ß√£o perigosa."
        }
        issues = []
        for pattern, msg in dangerous_patterns.items():
            if re.search(pattern, code):
                issues.append(msg)
        
        if issues:
            return ValidationResult(status=ValidationStatus.WARNING, message=f"Padr√µes perigosos encontrados: {', '.join(issues)}", validator_name="Security")
        return ValidationResult(status=ValidationStatus.PASSED, message="Nenhum risco de seguran√ßa √≥bvio detectado.", validator_name="Security")

    def _validate_consistency(self, code: str, html: str) -> ValidationResult:
        """Verifica se os seletores no c√≥digo existem no HTML fornecido."""
        if not HAS_BS4:
            return ValidationResult(status=ValidationStatus.SKIPPED, message="BeautifulSoup n√£o dispon√≠vel para valida√ß√£o de consist√™ncia.", validator_name="Consistency")
        
        soup = BeautifulSoup(html, 'html.parser')
        selectors = re.findall(r'page\.(?:locator|click|fill)\( ŸÖÿ´ŸÑÿßŸã"|\["\\](.*?)\["\\]\)', code)
        missing = []
        for selector in selectors:
            try:
                if not soup.select_one(selector):
                    missing.append(selector)
            except Exception:
                missing.append(f"{selector} (seletor inv√°lido)")
        
        if missing:
            return ValidationResult(status=ValidationStatus.WARNING, message=f"Seletores n√£o encontrados no HTML: {', '.join(missing)}", validator_name="Consistency")
        return ValidationResult(status=ValidationStatus.PASSED, message="Todos os seletores parecem consistentes com o HTML.", validator_name="Consistency")

    def _assess_quality(self, code: str) -> ValidationResult:
        """Avalia a qualidade do c√≥digo com base em heur√≠sticas."""
        score = 1.0
        issues = []
        
        # Penaliza por uso de time.sleep()
        if "time.sleep" in code:
            score -= 0.3
            issues.append("Uso de 'time.sleep' em vez de esperas expl√≠citas do Playwright.")
        
        # Penaliza por falta de tratamento de erro
        if "try:" not in code and len(code.splitlines()) > 10:
            score -= 0.2
            issues.append("Falta de blocos try/except para tratamento de erros.")
            
        # Penaliza por falta de coment√°rios
        if "#" not in code and len(code.splitlines()) > 15:
            score -= 0.1
            issues.append("C√≥digo extenso sem coment√°rios.")

        if score < 1.0:
            return ValidationResult(status=ValidationStatus.WARNING, message=f"Pontos de melhoria de qualidade detectados. Issues: {' '.join(issues)}", score=score, validator_name="Quality")
        return ValidationResult(status=ValidationStatus.PASSED, message="C√≥digo segue boas pr√°ticas b√°sicas.", score=score, validator_name="Quality")

# --- Gerenciador de Templates de C√≥digo ---
class CodeTemplateManager:
    """Gerenciador de templates de c√≥digo reutiliz√°veis."""
    
    def __init__(self):
        self.templates = {
            'rpa_click_template': '''
# Template para clique em elemento
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

try:
    element = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.{selector_type}, "{selector_value}"))
    )
    element.click()
    logger.info(f"Clicou no elemento: {selector_value}")
except Exception as e:
    logger.error(f"Erro ao clicar no elemento: {e}")
    raise
''',
            
            'rpa_type_template': '''
# Template para digita√ß√£o em campo
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

try:
    element = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.{selector_type}, "{selector_value}"))
    )
    element.clear()
    element.send_keys("{text_to_type}")
    logger.info(f"Digitou no campo: {selector_value}")
except Exception as e:
    logger.error(f"Erro ao digitar no campo: {e}")
    raise
''',
            
            'error_handling_template': '''
# Template para tratamento de erro
import time
from selenium.common.exceptions import TimeoutException, NoSuchElementException

def {function_name}():
    max_retries = 3
    for attempt in range(max_retries):
        try:
            {main_code}
            return True
        except (TimeoutException, NoSuchElementException) as e:
            logger.warning(f"Tentativa {attempt + 1} falhou: {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                logger.error(f"Todas as tentativas falharam para: {function_name}")
                raise
        except Exception as e:
            logger.error(f"Erro inesperado em {function_name}: {e}")
            raise
    return False
''',
            
            'data_extraction_template': '''
# Template para extra√ß√£o de dados
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

try:
    elements = WebDriverWait(driver, 10).until(
        EC.presence_of_all_elements_located((By.{selector_type}, "{selector_value}"))
    )
    
    extracted_data = []
    for element in elements:
        data = {{
            'text': element.text.strip(),
            'value': element.get_attribute('value') if element.get_attribute('value') else '',
            'href': element.get_attribute('href') if element.get_attribute('href') else ''
        }}
        extracted_data.append(data)
    
    logger.info(f"Extraiu {len(extracted_data)} elementos")
    return extracted_data
    
except Exception as e:
    logger.error(f"Erro na extra√ß√£o de dados: {e}")
    return []
'''
        }
    
    def get_template(self, template_type: str) -> Optional[str]:
        """Retorna um template de c√≥digo espec√≠fico."""
        return self.templates.get(template_type)
    
    def apply_template(self, template: str, data: Dict[str, Any]) -> str:
        """Aplica dados ao template substituindo placeholders."""
        try:
            return template.format(**data)
        except KeyError as e:
            logger.error(f"Placeholder n√£o encontrado no template: {e}")
            return template
        except Exception as e:
            logger.error(f"Erro ao aplicar template: {e}")
            return template
    
    def list_templates(self) -> List[str]:
        """Lista todos os templates dispon√≠veis."""
        return list(self.templates.keys())

# --- Framework √âtico Simplificado (para integra√ß√£o) ---
@dataclass
class EthicalValidationResult:
    """Resultado da valida√ß√£o √©tica."""
    is_approved: bool
    reason: str
    risk_score: float
    requires_confirmation: bool = False

class SimpleEthicalFramework:
    """Framework √©tico simplificado para valida√ß√£o de a√ß√µes."""
    
    def __init__(self):
        self.risk_keywords = [
            'delete', 'remove', 'drop', 'truncate', 'rm -rf',
            'format', 'destroy', 'wipe', 'system', 'admin',
            'password', 'private', 'secret', 'token'
        ]
        
        self.high_risk_actions = [
            'file_deletion', 'system_modification', 'data_destruction',
            'privilege_escalation', 'network_access'
        ]
    
    def validate_action(self, action_context: Dict[str, Any]) -> EthicalValidationResult:
        """Valida a√ß√£o do ponto de vista √©tico."""
        risk_score = 1.0
        warnings = []
        
        # Verifica palavras-chave de risco
        description_lower = action_context.get('description', '').lower()
        for keyword in self.risk_keywords:
            if keyword in description_lower:
                risk_score *= 0.7
                warnings.append(f"Palavra-chave de risco detectada: {keyword}")
        
        # Verifica tipo de a√ß√£o
        action_type = action_context.get('action_type', '')
        if action_type in self.high_risk_actions:
            risk_score *= 0.5
            warnings.append(f"Tipo de a√ß√£o de alto risco: {action_type}")
        
        # Verifica par√¢metros
        if 'generated_code' in action_context.get('parameters', {}):
            code = action_context['parameters']['generated_code']
            for keyword in self.risk_keywords:
                if keyword in code.lower():
                    risk_score *= 0.6
                    warnings.append(f"C√≥digo cont√©m opera√ß√£o de risco: {keyword}")
        
        # Determina aprova√ß√£o
        is_approved = risk_score > 0.5
        requires_confirmation = 0.3 < risk_score <= 0.7
        
        reason = "A√ß√£o aprovada" if is_approved else "A√ß√£o rejeitada por riscos √©ticos"
        if warnings:
            reason += f". Avisos: {'; '.join(warnings)}"
        
        return EthicalValidationResult(
            is_approved=is_approved,
            reason=reason,
            risk_score=risk_score,
            requires_confirmation=requires_confirmation
        )

# --- Sistema de Feedback Metacognitivo ---
class ACCMetacognitiveFeedback:
    """Sistema de feedback metacognitivo para o ACC."""
    
    def __init__(self):
        self.generation_history = []
        self.success_patterns = {}
        self.failure_patterns = {}
    
    def record_generation_attempt(self, context: Dict[str, Any], 
                                result: Dict[str, Any]) -> None:
        """Registra tentativa de gera√ß√£o para aprendizado."""
        record = {
            'timestamp': time.time(),
            'context_hash': hash(str(sorted(context.items()))),
            'success': result.get('success', False),
            'confidence': result.get('confidence', 0.0),
            'used_model': result.get('used_model', 'unknown'),
            'quality_score': result.get('quality_score', 0.0),
            'context_type': self._classify_context(context),
            'outcome_type': self._classify_outcome(context.get('desired_outcome', ''))
        }
        
        self.generation_history.append(record)
        self._update_patterns(record)
    
    def _classify_context(self, context: Dict[str, Any]) -> str:
        """Classifica tipo de contexto."""
        if 'error_message' in context:
            return 'error_correction'
        elif 'html_snapshot' in context:
            return 'web_automation'
        else:
            return 'general'
    
    def _classify_outcome(self, desired_outcome: str) -> str:
        """Classifica tipo de resultado desejado."""
        outcome_lower = desired_outcome.lower()
        if 'click' in outcome_lower:
            return 'click_action'
        elif 'type' in outcome_lower or 'digitar' in outcome_lower:
            return 'input_action'
        elif 'extract' in outcome_lower:
            return 'data_extraction'
        else:
            return 'other'
    
    def _update_patterns(self, record: Dict[str, Any]) -> None:
        """Atualiza padr√µes de sucesso/falha."""
        pattern_key = f"{record['context_type']}_{record['outcome_type']}"
        
        if record['success']:
            if pattern_key not in self.success_patterns:
                self.success_patterns[pattern_key] = []
            self.success_patterns[pattern_key].append(record)
        else:
            if pattern_key not in self.failure_patterns:
                self.failure_patterns[pattern_key] = []
            self.failure_patterns[pattern_key].append(record)
    
    def get_recommendations(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Fornece recomenda√ß√µes baseadas no hist√≥rico."""
        context_type = self._classify_context(context)
        outcome_type = self._classify_outcome(context.get('desired_outcome', ''))
        pattern_key = f"{context_type}_{outcome_type}"
        
        recommendations = {
            'suggested_model': 'auto',
            'expected_confidence': 0.5,
            'risk_factors': [],
            'success_probability': 0.5
        }
        
        # An√°lise de padr√µes de sucesso
        if pattern_key in self.success_patterns:
            successes = self.success_patterns[pattern_key]
            if successes:
                # Modelo mais bem-sucedido
                model_counts = {}
                for success in successes[-10:]:  # √öltimos 10 sucessos
                    model = success['used_model']
                    model_counts[model] = model_counts.get(model, 0) + 1
                
                if model_counts:
                    recommendations['suggested_model'] = max(model_counts, key=model_counts.get)
                
                # Confian√ßa m√©dia
                avg_confidence = sum(s['confidence'] for s in successes[-10:]) / len(successes[-10:])
                recommendations['expected_confidence'] = avg_confidence
        
        # An√°lise de padr√µes de falha
        if pattern_key in self.failure_patterns:
            failures = self.failure_patterns[pattern_key]
            total_attempts = len(self.success_patterns.get(pattern_key, [])) + len(failures)
            recommendations['success_probability'] = len(self.success_patterns.get(pattern_key, [])) / max(total_attempts, 1)
            
            # Identifica fatores de risco comuns
            for failure in failures[-5:]:  # √öltimas 5 falhas
                if failure.get('ethical_issue'):
                    recommendations['risk_factors'].append('ethical_concerns')
                if failure.get('validation_failed'):
                    recommendations['risk_factors'].append('code_quality')
        
        return recommendations

# --- Sistema de Execu√ß√£o Simulada para Teste ---
class ExecutionSandbox:
    """Sandbox simulado para execu√ß√£o de c√≥digo gerado."""
    
    def __init__(self):
        self.execution_history = []
        self.logger = logger
    
    async def simulate_execution(self, code: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Simula execu√ß√£o do c√≥digo gerado."""
        self.logger.info("=== SIMULA√á√ÉO DE EXECU√á√ÉO ===")
        self.logger.info(f"C√≥digo a ser executado:\n{code}")
        
        # An√°lise b√°sica do c√≥digo para simula√ß√£o
        result = {
            'success': True,
            'execution_time': 2.5,  # Simulado
            'output': '',
            'errors': [],
            'side_effects': []
        }
        
        # Simula diferentes cen√°rios baseados no c√≥digo
        if 'click()' in code:
            result['output'] = 'Elemento clicado com sucesso'
            result['side_effects'].append('page_navigation')
        elif 'send_keys(' in code:
            result['output'] = 'Texto digitado no campo'
            result['side_effects'].append('form_input')
        elif 'find_element' in code and 'TimeoutException' in code:
            result['output'] = 'Elemento encontrado ap√≥s aguardar'
        
        # Simula falhas ocasionais
        import random
        if random.random() < 0.1:  # 10% de chance de falha
            result['success'] = False
            result['errors'].append('Elemento n√£o encontrado na simula√ß√£o')
        
        # Registra hist√≥rico
        execution_record = {
            'timestamp': time.time(),
            'code_hash': hash(code),
            'context': context,
            'result': result
        }
        self.execution_history.append(execution_record)
        
        self.logger.info(f"Resultado da simula√ß√£o: {result}")
        return result

# --- Gerador de C√≥digo Principal ---

class AdvancedCodeGenerator:
    """Orquestra o processo de gera√ß√£o e valida√ß√£o de c√≥digo."""

    def __init__(self, llm_integration: Optional[LLMIntegration] = None, max_iterations: int = 2,
                 ethical_framework: Optional[SimpleEthicalFramework] = None,
                 metacognitive_feedback: Optional[ACCMetacognitiveFeedback] = None,
                 execution_sandbox: Optional[ExecutionSandbox] = None):
        self.llm = llm_integration or LLMIntegration()
        self.validator = CodeValidator()
        self.max_iterations = max_iterations
        self.ethical_framework = ethical_framework or SimpleEthicalFramework()
        self.metacognitive_feedback = metacognitive_feedback or ACCMetacognitiveFeedback()
        self.execution_sandbox = execution_sandbox or ExecutionSandbox()
        self.template_manager = CodeTemplateManager()

    def _build_optimized_prompt(self, context: ProblemContext, issues: List[str] = None) -> str:
        """Constr√≥i um prompt otimizado para o LLM."""
        prompt = f"""
Voc√™ √© um especialista em automa√ß√£o web Python com Playwright. Gere apenas o bloco de c√≥digo Python solicitado, sem explica√ß√µes adicionais.

**Objetivo:** {context.description}
**URL Alvo:** {context.target_url or "N√£o especificada"}
**Framework:** {context.framework}
"""
        html_preview = (context.html_snapshot[:1500] + "...") if context.html_snapshot and len(context.html_snapshot) > 1500 else context.html_snapshot
        if html_preview:
            prompt += f"\n**Contexto da P√°gina (Preview do HTML):**\n```html\n{html_preview}\n```\n"

        if context.existing_code:
            prompt += f"\n**C√≥digo Existente (para reparo):**\n```python\n{context.existing_code}\n```\n"

        if issues:
            prompt += "\n**Problemas na Vers√£o Anterior (corrija estes pontos):**\n"
            prompt += "\n".join(f"- {issue}" for issue in issues)
            prompt += "\n"

        prompt += """
**Instru√ß√µes Finais:**
1. Gere um script Python completo e funcional.
2. Use esperas expl√≠citas do Playwright (`page.wait_for_selector`, etc.) em vez de `time.sleep()`.
3. Inclua blocos `try/except` para tratamento de erros robusto.
4. Adicione logging para informar sobre o progresso.
5. Retorne APENAS o c√≥digo dentro de um bloco ```python.
"""
        return prompt

    async def generate_solution(self, context: ProblemContext) -> GeneratedSolution:
        """Ciclo completo de gera√ß√£o e auto-melhoria."""
        logger.info(f"Iniciando gera√ß√£o de solu√ß√£o para: {context.description}")
        best_solution = GeneratedSolution(code="", quality_score=-1)
        issues_for_next_iteration = []

        for i in range(self.max_iterations):
            logger.info(f"--- Itera√ß√£o {i + 1}/{self.max_iterations} ---")
            prompt = self._build_optimized_prompt(context, issues_for_next_iteration)
            generated_code_response = await self.llm.generate_text_with_code(prompt)
            generated_code = generated_code_response.get('generated_code', '')

            if not generated_code:
                logger.warning("Falha na gera√ß√£o de c√≥digo pelo LLM.")
                continue

            validation_results = self.validator.validate_all(generated_code, context)
            
            # Valida√ß√£o √âtica
            ethical_context = {
                "action_type": "code_generation",
                "description": context.description,
                "parameters": {"generated_code": generated_code}
            }
            ethical_validation = self.ethical_framework.validate_action(ethical_context)
            
            if not ethical_validation.is_approved:
                logger.warning(f"C√≥digo reprovado pela √©tica: {ethical_validation.reason}")
                validation_results.append(ValidationResult(
                    status=ValidationStatus.FAILED, 
                    message=f"Reprovado pela √©tica: {ethical_validation.reason}", 
                    validator_name="Ethical"
                ))

            # Simula√ß√£o de Execu√ß√£o
            simulation_result = await self.execution_sandbox.simulate_execution(generated_code, context)
            if not simulation_result['success']:
                logger.warning(f"Simula√ß√£o de execu√ß√£o falhou: {simulation_result['errors']}")
                validation_results.append(ValidationResult(
                    status=ValidationStatus.FAILED, 
                    message=f"Simula√ß√£o falhou: {simulation_result['errors']}", 
                    validator_name="Simulation"
                ))

            # Calcula o score de qualidade
            scored_results = [r.score for r in validation_results if r.score is not None]
            quality_score = sum(scored_results) / len(scored_results) if scored_results else 0.5
            
            current_solution = GeneratedSolution(generated_code, validation_results, quality_score)
            
            if quality_score > best_solution.quality_score:
                logger.info(f"Nova melhor solu√ß√£o encontrada (Score: {quality_score:.2f})")
                best_solution = current_solution

            if current_solution.is_valid and quality_score > 0.9:
                logger.info("Solu√ß√£o de alta qualidade encontrada, finalizando itera√ß√µes.")
                break
            
            # Prepara para a pr√≥xima itera√ß√£o
            issues_for_next_iteration = [res.message for res in validation_results if res.status != ValidationStatus.PASSED]
            if not issues_for_next_iteration:
                logger.info("Nenhum problema encontrado, finalizando itera√ß√µes.")
                break
        
        # Registrar feedback metacognitivo
        self.metacognitive_feedback.record_generation_attempt(context.__dict__, best_solution.__dict__)

        if not best_solution.code:
             return GeneratedSolution(code="# Falha ao gerar c√≥digo ap√≥s todas as itera√ß√µes.", validation_results=[
                ValidationResult(status=ValidationStatus.FAILED, message="Nenhum c√≥digo foi gerado.", validator_name="Generator")
             ])

        logger.info(f"Gera√ß√£o conclu√≠da. Score final da melhor solu√ß√£o: {best_solution.quality_score:.2f}")
        return best_solution

# --- Fachada para Integra√ß√£o Simplificada ---

class AutoCodeConstructorFacade:
    """Ponto de entrada simplificado para o sistema de gera√ß√£o de c√≥digo."""

    def __init__(self, llm_integration: Optional[LLMIntegration] = None, max_iterations: int = 2,
                 ethical_framework: Optional[SimpleEthicalFramework] = None,
                 metacognitive_feedback: Optional[ACCMetacognitiveFeedback] = None,
                 execution_sandbox: Optional[ExecutionSandbox] = None):
        try:
            self.generator = AdvancedCodeGenerator(
                llm_integration=llm_integration or LLMIntegration(),
                max_iterations=max_iterations,
                ethical_framework=ethical_framework or SimpleEthicalFramework(),
                metacognitive_feedback=metacognitive_feedback or ACCMetacognitiveFeedback(),
                execution_sandbox=execution_sandbox or ExecutionSandbox()
            )
            self.is_ready = True
            logger.info("Fachada do Construtor de C√≥digo inicializada com sucesso.")
        except Exception as e:
            self.generator = None
            self.is_ready = False
            logger.critical(f"Falha ao inicializar a fachada do construtor de c√≥digo: {e}")

    async def generate_automation_code(self, error_context: str, html_content: str, target_action: str, **kwargs) -> Dict[str, Any]:
        """
        Gera um script de automa√ß√£o com base no contexto de um erro ou tarefa.

        Args:
            error_context (str): Descri√ß√£o do erro ou da automa√ß√£o falha.
            html_content (str): Snapshot do HTML da p√°gina no momento do erro.
            target_action (str): Descri√ß√£o da a√ß√£o que deveria ser executada.

        Returns:
            Um dicion√°rio contendo o c√≥digo gerado e uma explica√ß√£o.
        """
        if not self.is_ready:
            return {
                "success": False,
                "error": "O construtor de c√≥digo n√£o est√° pronto. Verifique as depend√™ncias (ex: requests)."
            }

        problem_description = f"Ocorreu um erro: '{error_context}'. A automa√ß√£o deveria '{target_action}'."
        
        context = ProblemContext(
            description=problem_description,
            html_snapshot=html_content,
            target_url=kwargs.get('target_url', "URL n√£o especificada no contexto do erro"),
            existing_code=kwargs.get('existing_code')
        )
        
        try:
            solution = await self.generator.generate_solution(context)
            
            if solution.is_valid:
                explanation = "O script gerado tenta corrigir o problema com base no contexto fornecido. Ele usa esperas expl√≠citas e seletores robustos para maior confiabilidade."
                return {
                    "success": True,
                    "code": solution.code,
                    "explanation": explanation,
                    "quality_score": solution.quality_score,
                    "validation_results": [asdict(r) for r in solution.validation_results]
                }
            else:
                failed_checks = [f"{r.validator_name}: {r.message}" for r in solution.validation_results if r.status == ValidationStatus.FAILED]
                return {
                    "success": False,
                    "error": "O c√≥digo gerado n√£o passou nas valida√ß√µes cr√≠ticas.",
                    "details": {
                        "failed_checks": failed_checks,
                        "generated_code_attempt": solution.code,
                        "validation_results": [asdict(r) for r in solution.validation_results]
                    }
                }
        except Exception as e:
            logger.error(f"Erro cr√≠tico no processo de gera√ß√£o de c√≥digo: {e}", exc_info=True)
            return {
                "success": False,
                "error": f"Uma exce√ß√£o interna ocorreu durante a gera√ß√£o do c√≥digo: {e}"
            }

# --- Bloco de Demonstra√ß√£o (para testes) ---
async def main_demo():
    """Fun√ß√£o de demonstra√ß√£o para testar o m√≥dulo de forma independente."""
    logger.info("--- INICIANDO DEMONSTRA√á√ÉO DO AUTO CONSTRUTOR DE C√ìDIGO UNIFICADO ---")
    
    facade = AutoCodeConstructorFacade()
    if not facade.is_ready:
        logger.error("A demonstra√ß√£o n√£o pode continuar pois a fachada n√£o foi inicializada.")
        return

    # Cen√°rio de problema
    html_exemplo = """
    <html><body>
        <form>
            <label for="user">Usu√°rio:</label>
            <input type="email" id="email-field" name="username">
            <label for="pass">Senha:</label>
            <input type="password" id="password-field" name="password">
            <button type="submit" class="btn-login">Entrar</button>
        </form>
    </body></html>
    """
    
    resultado = await facade.generate_automation_code(
        error_context="Elemento 'login-button' n√£o encontrado.",
        html_content=html_exemplo,
        target_action="Fazer login no site preenchendo email e senha e clicando no bot√£o 'Entrar'."
    )
    
    print("\n" + "="*50)
    print("RESULTADO DA DEMONSTRA√á√ÉO")
    print("="*50)
    
    if resultado.get("success"):
        print("‚úÖ Gera√ß√£o de c√≥digo bem-sucedida!")
        print(f"üìä Score de Qualidade: {resultado.get('quality_score', 0):.2f}\n")
        print("--- C√ìDIGO GERADO ---")
        print(resultado.get("code"))
        print("\n--- EXPLICA√á√ÉO ---")
        print(resultado.get("explanation"))
        print("\n--- RESULTADOS DA VALIDA√á√ÉO ---")
        for res in resultado.get("validation_results", []):
            print(f"  - {res['validator_name']}: {res['status'].value} - {res['message']}")

    else:
        print("‚ùå Falha na gera√ß√£o de c√≥digo.")
        print(f"Erro: {resultado.get('error')}")
        if "details" in resultado:
            print("Detalhes:", json.dumps(resultado["details"], indent=2))
            
    print("="*50)


if __name__ == "__main__":
    asyncio.run(main_demo())